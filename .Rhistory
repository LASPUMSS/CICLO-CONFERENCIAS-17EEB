library("neuralnet")
library(MASS)
#-> Para asegurar replicabilidad de los resultados
set.seed(123)
#-> Importar la base de datos
data = Boston
str(data) # obtener una vista de los datos
#-> En redes neuronales, se deben normalizar los datos, para mejorar ajuste
#--> datos sin unidades, en la misma escala.
max_data = apply(data, 2, max)
min_data = apply(data, 2, min)
#--> x_{scaled} = \frac{x-x_{min}}{x_{max}-x_{min}}
data_scaled = scale(data,center = min_data, scale = max_data - min_data)
#--> Se toma la muestra completa y se rompe en muestra de entrenamiento (70%) y
#--> de evaluacion (30%).
index = sample(1:nrow(data),round(0.70*nrow(data)))
train_data = as.data.frame(data_scaled[index,])
test_data = as.data.frame(data_scaled[-index,])
#--> Se implementa el procedimiento de estimacion de la ANN
#----> Se extraen los nombres de las variables
n = names(data)
#----> Se crear recursivamente la formula de la ANN a estimar dep ~ todas las exp
f = as.formula(paste("medv ~", paste(n[!n %in% "medv"], collapse = " + ")))
#----> Se estima la red neuronal con 10 nodos ocultos (hidden=10) y resultado lineal
net_data = neuralnet(f,data=train_data,hidden=10,linear.output=T)
#----> Se grafica la red resultante
plot(net_data)
#----> Con esta red es posible hacer prediccion directamente
predict_net_test = compute(net_data,test_data[,1:13])
#----> Se calcula el RMSE para este pronostico
predict_net_test_start = predict_net_test$net.result*(max(data$medv)-min(data$medv))+min(data$medv)
test_start = as.data.frame((test_data$medv)*(max(data$medv)-min(data$medv))+min(data$medv))
MSE.net_data = sum((test_start - predict_net_test_start)^2)/nrow(test_start)
#----> Para evaluar la capacidad predictiva de esta ANN, se contrasta contra una
#----> regresion lineal.
#----> Se estima el modelo
Regression_Model = lm(medv~., data=data)
summary(Regression_Model)
#----> Se extrae la muestra de evaluacion
test = data[-index,]
#----> Se predice sobre la muestra de evaluacion
predict_lm = predict(Regression_Model,test)
#----> Se calcula el RMSE
MSE.lm = sum((predict_lm - test$medv)^2)/nrow(test)
#----> Se contrastan los dos RMSE
MSE.net_data
MSE.lm
#--> Notese que la red neural tiene un menor RMSE que la regresion lineal multiple.
# Limpiar workspace
rm(list = ls())
#-> Importar librerias requeridas
library(rsample)      # Dividir muestras
library(rpart)        # Implementacion basica de la metodologia
library(rpart.plot)   # Graficos de regression trees
library(caret)        # Un paquete que permite implementar varias tecnicas de ML
library(ipred)        # Bagging
library(AmesHousing)  # Base de datos para trabajar
library(ggplot2)
library(tidyr)
library(dplyr)
#-> Creacion de muestras de entrenamiento (70%) y evaluacion (30%).
set.seed(123)
ames_split = initial_split(AmesHousing::make_ames(), prop = .7)
ames_train = training(ames_split)
ames_test  = testing(ames_split)
#-> Implementacion basica
#-> Para hacer regression trees es necesario usar "anova" en la opcion "method"
m1 <- rpart(
formula = Sale_Price ~ .,
data    = ames_train,
method  = "anova"
)
m1
#-> Es posible ver esta misma informacion, pero visualmente
rpart.plot(m1)
#-> Si se desea ver como se disminuye el error a medida que el arbol va creciendo
#-> se puede usar la siguiente instruccion
plotcp(m1)
#-> Noten como el error no mejora ante cada nuevo nodo.
#-> Si se quiere evaluar la totalidad del arbol, sin podar, y ver como se comporta
#-> este indicador, se debe hacer lo siguiente:
#-> CLAVE: cp=0 desactiva el podado del arbol.
m2 = rpart(
formula = Sale_Price ~ .,
data    = ames_train,
method  = "anova",
control = list(cp = 0, xval = 10)
)
plotcp(m2)
abline(v = 12, lty = "dashed")
m1$cptable
#-> Igual, se puede tratar de refinar el arbol, mediante la calibracion de los
#-> hiperparametros del modelo: minsplit es el numero minimo de datos en cada nodo
#-> maxdepth es el numero maximo de nodos internos.
#-> Por ejemplo, se va a crecer un arbol con 10 obs por nodo y maximo 12 nodos internos
m3 <- rpart(
formula = Sale_Price ~ .,
data    = ames_train,
method  = "anova",
control = list(minsplit = 10, maxdepth = 12, xval = 10)
)
m3$cptable
#-> Por supuesto, este procedimiento puede hacerse automaticamente, sin tener que
#-> repetir el codigo para cada combinacion de hiperparametros.
hyper_grid <- expand.grid(
minsplit = seq(5, 20, 1),
maxdepth = seq(8, 15, 1)
)
head(hyper_grid)
#--> numero total de combinaciones
nrow(hyper_grid)
#-> Se aplican los experimentos
models = list()
for (i in 1:nrow(hyper_grid)) {
# get minsplit, maxdepth values at row i
minsplit = hyper_grid$minsplit[i]
maxdepth = hyper_grid$maxdepth[i]
# train a model and store in the list
models[[i]] = rpart(
formula = Sale_Price ~ .,
data    = ames_train,
method  = "anova",
control = list(minsplit = minsplit, maxdepth = maxdepth)
)
}
#-> Con esta funcion se puede hallar la combinacion optima de hiperparametros
#-> de todos los experimentos hechos.
#--> Se halla el minimo numero de nodos
get_cp = function(x) {
min    = which.min(x$cptable[, "xerror"])
cp = x$cptable[min, "CP"]
}
#--> Se halla el minimo error
get_min_error = function(x) {
min    = which.min(x$cptable[, "xerror"])
xerror = x$cptable[min, "xerror"]
}
hyper_grid %>%
mutate(
cp    = purrr::map_dbl(models, get_cp),
error = purrr::map_dbl(models, get_min_error)
) %>%
arrange(error) %>%
top_n(-5, wt = error)
optimal_tree = rpart(
formula = Sale_Price ~ .,
data    = ames_train,
method  = "anova",
control = list(minsplit = 6, maxdepth = 10, cp = 0.01)
)
#-> Hagamos prediccion con este modelo
pred = predict(optimal_tree, newdata = ames_test)
#-> Calculo del RMSE
RMSE_rpart = RMSE(pred = pred, obs = ames_test$Sale_Price)
#-> Grafico observado vs pronosticado
#--> Grafico de comparacion
plot(pred, type = "l", lty=1)
lines(ames_test$Sale_Price, type = "l", lty=1, col=3)
#-------------------------------------------------------------------------------
# Bagging
# Recuerden que este procedimiento esta entre Regression Tree y Random Forest
#-------------------------------------------------------------------------------
#-> Semilla para hacer reproducible el ejercicio
set.seed(123)
# Entrenar el modelo
bagged_m1 = bagging(
formula = Sale_Price ~ .,
data    = ames_train,
coob    = TRUE
)
bagged_m1
#-> En este acercamiento, mientras mas arboles se tenga, mejor. Sin embargo, se puede
#-> hallar un valor optimo de estos
#--> Evaluaremos una senda de entre 10 y 50 arboles
ntree = 10:50
#--> espacio para guardar los valores de OOB RMSE
rmse = vector(mode = "numeric", length = length(ntree))
#--> Implementando el experimento
for (i in seq_along(ntree)) {
set.seed(123)
#---> Implementar el modelo
model = bagging(
formula = Sale_Price ~ .,
data    = ames_train,
coob    = TRUE,
nbagg   = ntree[i]
)
#---> obtener el OOB error
rmse[i] = model$err
}
#--> Graficamos el resultado
plot(ntree, rmse, type = 'l', lwd = 2)
abline(v = 25, col = "red", lty = "dashed")
#-> Se especifica el espacio para hacer validacion cruzada
#-> 10-fold significa partir la muestra en 10 partes, 9 de entrenamiento, una de
#-> evaluacion y hacer 10 veces cada iteracion y guardar los residuales
ctrl = trainControl(method = "cv",  number = 10)
#-> implementar el modelo
bagged_cv = train(
Sale_Price ~ .,
data = ames_train,
method = "treebag",
trControl = ctrl,
importance = TRUE
)
#-> Revisar los resultados
bagged_cv
#-> Podemos graficar cuales son las variables mas importantes
plot(varImp(bagged_cv), 20)
#-> Podemos implementar prediccion y compararlo con el metodo anterior
pred_cv = predict(bagged_cv, ames_test)
#--> Grafico de comparacion
plot(pred, type = "l", lty=1)
lines(pred_cv, type = "l", lty=1, col=4)
lines(ames_test$Sale_Price, type = "l", lty=1, col=3)
#--> RMSE para este arbol
RMSE_cv = RMSE(pred_cv, ames_test$Sale_Price)
RMSE_rpart
RMSE_cv
# Limpiar workspace
rm(list = ls())
# Cargar librerias necesarias para estimacion
set.seed(123)
library(glmnet)  # clave para implementar Ridge
library(dplyr)
library(psych)
library(data.table)
library(ggplot2)
library(ggfortify)
library(caret)
#-> Se alistan las variables explicativas
setwd("D:/Dropbox/BR/Depto_Macro/Cursos/Banco Central de Bolivia/Códigos/Proyecciones lineales de alta dimensionalidad")
gdp.hf <- fread('us_gdp_monthly_ch12_sec6.csv',
select = c('date', 'coinc_indicators_index', 'employees', 'ind_prod', 'pers_inc', 'sales'))
# Limpiar workspace
rm(list = ls())
# Cargar librerias necesarias para estimacion
set.seed(123)
library(glmnet)  # clave para implementar Ridge
library(dplyr)
library(psych)
library(data.table)
library(ggplot2)
library(ggfortify)
library(caret)
#-> Se alistan las variables explicativas
# setwd("D:/Dropbox/BR/Depto_Macro/Cursos/Banco Central de Bolivia/Códigos/Proyecciones lineales de alta dimensionalidad")
gdp.hf <- fread('Proyecciones lineales de alta dimensionalidad/us_gdp_monthly_ch12_sec6.csv',
select = c('date', 'coinc_indicators_index', 'employees', 'ind_prod', 'pers_inc', 'sales'))
gdp.hf[, date := as.Date(date, format = '%m/%d/%Y')]
gdp.hf[, qtr := rep(1:112, each = 3)]
gdp.hf[, c('CI', 'E', 'IP', 'INC', 'SA') :=
list(mean(coinc_indicators_index), mean(employees), mean(ind_prod), mean(pers_inc), mean(sales)), by = qtr]
gdp.xs = unique(gdp.hf[date <= '2012-12-01' & date >= '1985-04-01', .(date, CI, E, IP, INC, SA)])
#-> Se alista la variable explicada
gdp.lf = fread('usgdp_qtr_ch13_sec6.csv')
gdp.lf[, date := as.Date(date, format = '%m/%d/%Y')]
#-> Se alistan las variables explicativas
# setwd("D:/Dropbox/BR/Depto_Macro/Cursos/Banco Central de Bolivia/Códigos/Proyecciones lineales de alta dimensionalidad")
gdp.hf <- fread('Proyecciones lineales de alta dimensionalidad/us_gdp_monthly_ch12_sec6.csv',
select = c('date', 'coinc_indicators_index', 'employees', 'ind_prod', 'pers_inc', 'sales'))
gdp.hf[, date := as.Date(date, format = '%m/%d/%Y')]
gdp.hf[, qtr := rep(1:112, each = 3)]
gdp.hf[, c('CI', 'E', 'IP', 'INC', 'SA') :=
list(mean(coinc_indicators_index), mean(employees), mean(ind_prod), mean(pers_inc), mean(sales)), by = qtr]
gdp.xs = unique(gdp.hf[date <= '2012-12-01' & date >= '1985-04-01', .(date, CI, E, IP, INC, SA)])
#-> Se alista la variable explicada
gdp.lf = fread('usgdp_qtr_ch13_sec6.csv')
#-> Se alista la variable explicada
gdp.lf = fread('Proyecciones lineales de alta dimensionalidad/usgdp_qtr_ch13_sec6.csv')
gdp.lf[, date := as.Date(date, format = '%m/%d/%Y')]
gdp = unique(gdp.lf[date <= '2012-10-01', .(date, gdp)])
#-> Base de datos a trabajar
gdp_us = merge(gdp, gdp.xs, by="date")
#-> Se estandariza la variable explicada
y = gdp_us %>% select(gdp) %>% scale(center = TRUE, scale = FALSE) %>% as.matrix()
#-> Se transforman los datos para dejarlos como objetos matriciales
#-> En glmnet, las xs se estandarizan automaticamente
X = gdp_us  %>% select(-c(gdp, date)) %>% as.matrix()
#--> Se genera una secuencia de valores de \lambda para evaluar el que minimiza RMSE
lambdas_to_try = 10^seq(-2, 5, length.out = 100)
#--> Clave: alpha=0 implementa ridge en este procedimiento
ridge_cv = cv.glmnet(X, y, alpha = 0, lambda = lambdas_to_try,
standardize = TRUE, nfolds = 10)
#--> Graficar los resultados de la validacion cruzada
plot(ridge_cv)
#--> Se escoge el \lambda que minimiza RMSE - mejor pronostico (validacion cruzada)
lambda_cv = ridge_cv$lambda.min
#-> Se estima el mejor modelo, se estrae RRS y R cuadrado
model_cv = glmnet(X, y, alpha = 0, lambda = lambda_cv, standardize = TRUE)
model_cv$beta
#--> Pronostico por dentro de muestra
y_hat_cv = predict(model_cv, X)
plot(y, type = "l", lty=1)
lines(y_hat_cv, type = "l", lty=1, col=4)
#--> Se computa suma de residuos al cuadrado
ssr_cv = t(y - y_hat_cv) %*% (y - y_hat_cv)
#--> Se calcula el R cuadrado
rsq_ridge_cv = cor(y, y_hat_cv)^2
rsq_ridge_cv
#-> Se puede escoger \lambda con criterios de informacion, también.
#--> Se estandarizan las variables x
X_scaled = scale(X)
aic = c()
bic = c()
for (lambda in seq(lambdas_to_try)) {
# Correr modelo
model = glmnet(X, y, alpha = 0, lambda = lambdas_to_try[lambda], standardize = TRUE)
# Se extraen los coeficientes y residuales (se quita la primera fila, corresponde a constante)
betas = as.vector((as.matrix(coef(model))[-1, ]))
resid = y - (X_scaled %*% betas)
# Se computa la matriz H y los grados de libertad
ld = lambdas_to_try[lambda] * diag(ncol(X_scaled))
H = X_scaled %*% solve(t(X_scaled) %*% X_scaled + ld) %*% t(X_scaled)
df = tr(H)
# Se computan los criterios de informacion
aic[lambda] = nrow(X_scaled) * log(t(resid) %*% resid) + 2 * df
bic[lambda] = nrow(X_scaled) * log(t(resid) %*% resid) + 2 * df * log(nrow(X_scaled))
}
# Grafico de los criterios de informacion vs cada lambda estimado
plot(log(lambdas_to_try), aic, col = "orange", type = "l",
ylab = "Information Criterion")
lines(log(lambdas_to_try), bic, col = "skyblue3")
legend("bottomleft", lwd = 1, col = c("orange", "skyblue3"), legend = c("AIC", "BIC"))
#--> Se hallan los \lambdas optimos, segun ambos criterios
lambda_aic = lambdas_to_try[which.min(aic)]
lambda_bic = lambdas_to_try[which.min(bic)]
#--> Se ajusta el modelo final, se calcula RSS y R cuadrado
model_aic = glmnet(X, y, alpha = 0, lambda = lambda_aic, standardize = TRUE)
y_hat_aic = predict(model_aic, X)
ssr_aic = t(y - y_hat_aic) %*% (y - y_hat_aic)
rsq_ridge_aic = cor(y, y_hat_aic)^2
model_bic = glmnet(X, y, alpha = 0, lambda = lambda_bic, standardize = TRUE)
y_hat_bic = predict(model_bic, X)
ssr_bic = t(y - y_hat_bic) %*% (y - y_hat_bic)
rsq_ridge_bic = cor(y, y_hat_bic)^2
#--> Notese como incrementar el lambda genera coeficientes cercanos a cero
#--> Cada linea muestra coeficientes para cada variable, para diferentes \lambdas.
#--> Cuanto mayor el lambda, mas coeficientes se vuelven cero.
res = glmnet(X, y, alpha = 0, lambda = lambdas_to_try, standardize = FALSE)
plot(res, xvar = "lambda")
legend("bottomright", lwd = 1, col = 1:6, legend = colnames(X), cex = .7)
#- Como se ve en las diapositivas, en LASSO se tiene una forma funcional para la
#- penalizacion. En lo demás, es muy similar a Ridge.
#--> Se genera una secuencia de valores de \lambda para evaluar el que minimiza RMSE
lambdas_to_try = 10^seq(-2, 5, length.out = 100)
#--> Clave: alpha=1 implementa LASSO en este procedimiento
lasso_cv = cv.glmnet(X, y, alpha = 1, lambda = lambdas_to_try,
standardize = TRUE, nfolds = 10)
#--> Graficar los resultados de la validacion cruzada
plot(lasso_cv)
# \lambda que minimiza MSE
lambda_cv = lasso_cv$lambda.min
# Se ajusta modelo final, calcula RSS y R cuadrado
model_cv = glmnet(X, y, alpha = 1, lambda = lambda_cv, standardize = TRUE)
y_hat_cv = predict(model_cv, X)
ssr_cv = t(y - y_hat_cv) %*% (y - y_hat_cv)
rsq_lasso_cv = cor(y, y_hat_cv)^2
#--> Notese como incrementar el lambda genera coeficientes cercanos a cero
#--> Cada linea muestra coeficientes para cada variable, para diferentes \lambdas.
#--> Cuanto mayor el lambda, mas coeficientes se vuelven cero.
res = glmnet(X, y, alpha = 1, lambda = lambdas_to_try, standardize = FALSE)
plot(res, xvar = "lambda")
legend("bottomright", lwd = 1, col = 1:6, legend = colnames(X), cex = .7)
#-> Ridge vs LASSO segun R cuadrado
rsq = cbind("R-squared" = c(rsq_ridge_cv, rsq_ridge_aic, rsq_ridge_bic, rsq_lasso_cv))
rownames(rsq) <- c("ridge validación cruzada", "ridge AIC", "ridge BIC", "lasso Validación cruzada")
print(rsq)
#-> Se determina los parametros del entrenamiento
train_control = trainControl(method = "repeatedcv",
number = 10,
repeats = 3,
search = "random",
verboseIter = TRUE, returnResamp = "all",
savePredictions = "all")
#-> Se entrena el modelo
elastic_net_model <- train(gdp ~ .,
data = cbind(y, X),
method = "glmnet",
preProcess = c("center", "scale"),
tuneLength = 25,
trControl = train_control)
#--> Exploremos que dice el aviso
elastic_net_model$results
#-> Resultado Elastic Net
elastic_net_model
#-> Se analiza el R cuadrado
#--> Prediccion del modelo
y_hat_enet <- predict(elastic_net_model, X)
y_hat_enet
#-> Calculo del R cuadrado
rsq_enet <- cor(y, y_hat_enet)^2
#-> Grafico del pronostico
plot(y, type = "l", lty=1)
lines(y_hat_enet, type = "l", lty=1, col=4)
#-> Grafico del pronostico
plot(y, type = "l", lty=1)
lines(y_hat_enet, type = "l", lty=1, col=4)
# Limpiar workspace
rm(list = ls())
#--> Importar librerias
library(midasr)
library(ggplot2)
library(ggfortify)
library(dplyr)
#--> Importar datos
data("USqgdp")
data("USpayems")
#--> Graficas los datos (¡siempre hacerlo!)
autoplot(USqgdp, xlab='Trimestres', ylab='PIB')
autoplot(USpayems, xlab='Meses', ylab='Empleo')
#--> Como empleados es una variable stock, se promedian datos mensuales para
#--> hallar el dato trimestral con el cual hacer la regresion para la baja frecuencia
#--> Agregar la variable en frecuencia mensual
x_q = aggregate(USpayems, nfrequency = 4)/3
plot(cbind(USqgdp, x_q), yax.flip = TRUE, col = "blue", frame.plot = TRUE,
main = expression("Series para Bridge"), xlab = "Trimestres")
#--> Estimar regresion Bridge para la baja frecuencia
#----> 1. Volver las series estacionarias
yg <- diff(log(USqgdp))*100
xg <- diff(log(x_q))*100
#----> 2. Estimando la regresion
dlgdp  = window(yg, end=c(2011,2))
dlpayr = window(xg, start=c(1947,2), end=c(2011,2))
bridge.lf = lm(dlgdp~dlpayr)
summary(bridge.lf)
#--> Modelo de pronostico para serie en alta frecuencia
bridge.flash = rep(0,3)
x_h = diff(log(USpayems))*100
#----> Idea: se va añadiendo de a un mes adicional observado del trimestre a pronosticar
#----> y se recalcula el pronostico de la serie trimetral objetivo.
for (n in 1:2) {
#----> Se estima un modelo AR(1), el mas simple
ar.fit     = ar(window(x_h, end=c(2011,6+n)), order.max=1, method='ols')
ar.predict = as.numeric(predict(ar.fit, n.ahead=3-n)$pred)
bridge.flash[n] = bridge.lf$coefficients[1]+
bridge.lf$coefficients[2]*sum(window(x_h, start=c(2011,7), end=c(2011,7+(n-1))), sum(ar.predict))/3
}
bridge.flash[3] = bridge.lf$coefficients[1]+
bridge.lf$coefficients[2]*window(xg, start=c(2011,3), end=c(2011,3))
window(yg, start=c(2011,2), end=c(2011,4))
bridge.flash
#--> Importar datos (otra vez)
data("USqgdp")
data("USpayems")
#--> Definir las fechas para los ultimos datos de cada serie
y <- window(USqgdp, end = c(2011, 2))
x <- window(USpayems, end = c(2011, 7))
#--> Calcular las diferencias logaritmicas de los datos
yg <- diff(log(y))*100
xg <- diff(log(x))*100
#--> Darle propiedad de series de tiempo a los datos
nx <- ts(c(NA, xg, NA, NA), start = start(x), frequency = 12)
ny <- ts(c(rep(NA, 33), yg, NA), start = start(x), frequency = 4)
#--> Graficas los datos (¡siempre hacerlo!)
plot.ts(nx, xlab = "Tiempo", ylab = "Porcentajes", col = 4, ylim = c(-5, 6))
lines(ny, col = 2)
#--> Homogenizar las muestras para implementar el ejercicio
xx <- window(nx, start = c(1985, 1), end = c(2009, 3))
yy <- window(ny, start = c(1985, 1), end = c(2009, 1))
#----> mls es el pedazo de codigo clave: mls(serie, rezagos, frecuencia de la serie, polinomio)
#----> En este caso se restringe MIDAS a 2 parametros y pol - almon
almon0 <- midas_r(yy ~ mls(yy, 1, 1) + mls(xx, 3:11, 3, nealmon), start = list(xx = c(2, 0.5)))
summary(almon0)
#----> 1. Se construye un cuadro con todos los experimentos a proponer
set_x1 <- expand_weights_lags(weights = c("nealmon", "nbeta"), from = 3,
to = c(11, 11), m = 1, start = list(nealmon = c(1, 1),
nbeta = rep(0.5, 3)))
#----> 2. Se construye el cuadro con todos los modelos estimables
eqs_ic <- midas_r_ic_table(yy ~ mls(yy, 1, 1) + mls(xx, 3:11, 3), table = list(xx = set_x1))
#----> 3. Se hallar el mejor modelo, usando AIC
modsel(eqs_ic, IC = "AIC", type = "restricted")
#----> a. Modelo escogido con AIC
mod_aic = midas_r(yy ~ mls(yy, 1, 1) + mls(xx, 3:11, 3, nealmon), start = list(xx = c(2, -0.5)))
summary(mod_aic)
#----> b. Modelo con polinomio beta
betam <- midas_r(yy ~ mls(yy, 1, 1) + mls(xx, 3:11, 3, nbeta),
start = list(xx = c(2, 1, 5)))
summary(betam)
#----> c. Modelo sin restricciones polinómicas
um <- midas_r(yy ~ mls(yy, 1, 1) + mls(xx, 3:11, 3), start = NULL)
summary(um)
#----> Estructura de la muestra completa
fulldata <- list(xx = window(nx, start = c(1985, 1), end = c(2011, 6)),
yy = window(ny, start = c(1985, 1), end = c(2011, 2)))
#----> Estructura de la muestra de estimacion
insample <- 1:length(yy)
#----> Estructura de la muestra de evaluacion
outsample <- (1:length(fulldata$yy))[-insample]
#----> Instruccion para evaluar la habilidad de pronostico de cada modelo
avgf <- average_forecast(list(mod_aic, betam, um), data = fulldata,
insample = insample, outsample = outsample)
#----> Se usa el Error Cuadratico Medio (RMSE) para realizar la evaluacion
eval_pron = sqrt(avgf$accuracy$individual$MSE.out.of.sample)
#----> En la consola aparecen los RMSE de cada modelo, en orden dado en avgf:
#----> (mod_aic, betam, um). En este caso, el mejor es el modelo um.
eval_pron
#-> Unrestricted MIDAS
#--> Ya hemos hecho un U-MIDAS sin quererlo. Sin embargo, la libreria tiene otra forma de hacerlo
#--> Se necesita tener los objetos en forma de "base de datos"
xumidas <- data.frame(window(nx, start = c(1985, 1), end = c(2009, 3)))
yumidas <- data.frame(window(ny, start = c(1985, 1), end = c(2009, 1)))
#--> Se usa comando midas_u
umidas_ex = midas_u(yy ~ mls(yy, 1, 1) + fmls(xx, 11, 3), list(yumidas, xumidas) )
#---> Sin embargo, esto es equivalente a hacer
umidas_ex_r = midas_r( yy ~ mls(yy, 1, 1) + mls(xx, 0:11, 3), start = NULL )
#---> En este caso, es conveniente seguir con el comando "midas_r" para implementar
#---> En este caso, es conveniente seguir con el comando "midas_r" para implementar
#---> U-MIDAS.
#---> En este caso, es conveniente seguir con el comando "midas_r" para implementar
#---> U-MIDAS.
582-490
